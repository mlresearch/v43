<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Teaching iCub to recognize objects using deep Convolutional Neural Networks | MLIS 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Teaching iCub to recognize objects using deep Convolutional Neural Networks">

  <meta name="citation_author" content="Pasquale, Giulia">

  <meta name="citation_author" content="Ciliberto, Carlo">

  <meta name="citation_author" content="Odone, Francesca">

  <meta name="citation_author" content="Rosasco, Lorenzo">

  <meta name="citation_author" content="Natale, Lorenzo">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of The 4th Workshop on Machine Learning for Interactive Systems">
<meta name="citation_firstpage" content="21">
<meta name="citation_lastpage" content="25">
<meta name="citation_pdf_url" content="pasquale15.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Teaching iCub to recognize objects using deep Convolutional Neural Networks</h1>

	<div id="authors">
	
		Giulia Pasquale,
	
		Carlo Ciliberto,
	
		Francesca Odone,
	
		Lorenzo Rosasco,
	
		Lorenzo Natale
	<br />
	</div>
	<div id="info">
		Proceedings of The 4th Workshop on Machine Learning for Interactive Systems,
		pp. 21–25, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Providing robots with accurate and robust visual recognition capabilities in the real-world today is a challenge which prevents the use of autonomous agents for concrete applications. Indeed, the majority of tasks, as manipulation and interaction with other agents, critically depends on the ability to visually recognize the entities involved in a scene. At the same time, computer vision systems based on deep Convolutional Neural Networks (CNNs) are marking a breakthrough in fields as large-scale image classification and retrieval. In this work we investigate how latest results on deep learning can advance the visual recognition capabilities of a robotic platform (the iCub humanoid robot) in a real-world scenario. We benchmark the performance of the resulting system on a new dataset of images depicting 28 objects, named iCubWorld28, that we plan on releasing. As in the spirit of the iCubWorld dataset series, this has been collected in a framework reflecting the typical iCub’s daily visual experience. Moreover, in this release we provide four different acquisition sessions, to test incremental learning capabilities over multiple days. Our study addresses the question: how many objects can the iCub recognize today?
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="pasquale15.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
