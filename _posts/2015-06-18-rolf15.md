---
title: Latent Goal Analysis for Dimension Reduction in Reinforcement Learning
abstract: In contrast to reinforcement learning, adaptive control formulations [Nguyen-Tuong
  and Peters, 2011] already come with expressive and typically low-dimensional goal
  and task representations, which have been generally considered more expressive than
  the RL setting [Kaelbling et al., 1996]. Goal and actual values in motor control
  define a relation similar [Rolf and Steil, 2014] to actual and target outputs in
  classical supervised learning settings by providing “directional information” in
  contrast to a mere “magnitude of an error” in reinforcement learning [Barto, 1994].
  Recent work [Rolf and Asada, 2014] however showed that these two problem formulations
  can be transformed into each other. Hence, highly descriptive task representations
  can be extracted out of reinforcement learning problems by transforming them into
  adaptive control problems. After introducing the method called Latent Goal Analysis,
  we discuss the possible application of this approach as dimension reduction technique
  in reinforcement learning. Experimental results in a web recommender scenario confirm
  the potential of this technique.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: rolf15
month: 0
tex_title: Latent Goal Analysis for Dimension Reduction in Reinforcement Learning
firstpage: 26
lastpage: 30
page: 26-30
sections: 
author:
- given: Matthias
  family: Rolf
- given: Minoru
  family: Asada
date: 2015-06-18
address: Lille, France
publisher: PMLR
container-title: Proceedings of The 4th Workshop on Machine Learning for Interactive
  Systems at ICML 2015
volume: '43'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 18
pdf: http://proceedings.mlr.press/v43/rolf15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
